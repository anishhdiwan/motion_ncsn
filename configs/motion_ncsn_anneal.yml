training:
  batch_size: 64
  n_epochs: 500000
  n_iters: 200001
  ngpu: 1
  snapshot_freq: 5000
  algo: 'dsm'
  anneal_power: 2.0

data:
  dataset: "pushT"
  logit_transform: False


model:
  sigma_begin: 1
  sigma_end: 0.01
  L: 3
  in_dim: 10
  encoder_hidden_layers: [265, 512]  
  latent_space_dim: 1024
  decoder_hidden_layers: [512, 256]
# The out dim is set to 1 internally (out_dim: 1)   


optim:
  weight_decay: 0.000
  optimizer: "Adam"
  lr: 0.0001
  beta1: 0.9
  amsgrad: false
